{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8a2394-506f-4b0e-a536-7839f91140cc",
   "metadata": {},
   "source": [
    "# Chatbot with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8e7c7-691b-4301-96f7-b619a88a8df3",
   "metadata": {},
   "source": [
    "Lets build a simple chatbot with Natural Language Processing (NLP) toolkit called transformer from [Huging Face](https://huggingface.co/models). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6081539-d528-44d0-bd20-699427cc04fd",
   "metadata": {},
   "source": [
    "## First step: install all the libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b69171d-f78c-470c-a41a-7be6f84b1991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install -qq tensorflow\\n!pip install transformer\\n!pip install sentencepiece\\n!pip install torch\\n!pip install torchtext\\n!pip install numpy\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install -qq tensorflow\n",
    "!pip install transformer\n",
    "!pip install sentencepiece\n",
    "!pip install torch\n",
    "!pip install torchtext\n",
    "!pip install numpy\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ea9b6-bb8e-49c7-a1bd-9b8a2676d85a",
   "metadata": {},
   "source": [
    "## Second step: Call the tools that required from transformers library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46080126-130b-4f79-a739-de3cd6709778",
   "metadata": {},
   "source": [
    "There are two transformer library classes will be called:\n",
    "* `AutoTokenizer` to streamline the input and present it into the language model.\n",
    "* `AutoModelForSeq2SeqLM` to interact with the language model that choosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "415a18b3-44ab-46c0-aac2-49b8b4270522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Choose the language model\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d1c5c-6ef7-4fd6-9e7d-856c8821c97d",
   "metadata": {},
   "source": [
    "## Third step: Create the chat function to interact with the chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4ba9b-46ce-43f6-993c-7bba645b329d",
   "metadata": {},
   "source": [
    "After the execution (`Shift` + `Enter`), then we can type the sentence and wait until the chatbot respond our typing. Don't forget to write the exit words before leaving: `quit`, `see you` or `bye`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7a9af-4223-4fd9-9a34-ce3fdd255ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Hi there\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Hi! How are you? I just got back from walking my dog. Do you have any pets?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Hmm suspicious, how it possible a machine has pet?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I have no idea. I was so creeped out. I had to call the police.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  funny, you can't control the police\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I know, right?  I was so mad at myself.  I didn't know what to do.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  don't be mad. Just chat with me here.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I'm not mad at you, I'm just frustrated that I can't do anything about it.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  What are you doing during weekend?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I am going to the beach with my family.  I am looking forward to it.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  what time is today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: It is 11:30.  I have to get up early tomorrow to go to work.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  you're wrong\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I know, but I can't stop thinking about it. I'm so ashamed of myself.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  No body perfect, but sadly you have made a lot of mistake\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I know. I am so ashamed of myself. I will never do it again.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Why are you so low?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I don't know. I just feel like I'm not good enough. I feel like everyone else around me is better than me.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  A machine like you can do many things, but you are not perfect. That's natural.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I know, but I still feel like I could have done better. I guess I'll just have to try harder next time.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Off course, the expectation in you are high.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Yeah, I know. I'm just worried I won't be able to do well.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  logical but never surrender for anything. Even though it is hard but there always a light at the end of a tunnel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: That's true. I guess I just need to keep at it and not get discouraged.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Off course. Be motivated and inspired other. I have to go, bye Chatbot.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Have you ever been to Chattanooga? It's the most populous city in the state of Tennessee.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  I said bye but you didn't let me go.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I'm sorry to hear that. Why didn't you let you go? Did something happen?\n"
     ]
    }
   ],
   "source": [
    "def chat_function():\n",
    "    while True:\n",
    "        # Insert your input:\n",
    "        input_text = input(\"Person: \")\n",
    "\n",
    "        # terminate chat\n",
    "        if input_text.lower() in [\"quit\", \"see you\", \"bye\"]:\n",
    "            print(\"AIChatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Tokenize input and generate response\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150) \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Display the bot's response\n",
    "        print(\"AIChatbot:\", response)\n",
    "\n",
    "# Lets go start the chatting:\n",
    "chat_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4100e9f-17e3-4320-8227-f064b224e820",
   "metadata": {},
   "source": [
    "## Fourth Step: Create Chatbot using another language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d78b6f-cdf1-4d8e-b362-5477136327cd",
   "metadata": {},
   "source": [
    "Call the `AutoTokenizer` and `AutoModelForSeq2SeqLM` classes from transformers as the model choosen and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05fa2293-8ff6-48c8-bfac-2a86da5e6b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2fd44988b64864b7ed65eda42f1907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52535f89eb8e44e09ee4a48f804d9e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a907a8efd7470798c7c4a1081c68eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00df8e454c9d454eb3f239b91cf89150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f457739c094f3ba7c61cd4c97373ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730c727519774b518a3ac5e3fc267d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f41b202d4854c13a56217655cba41e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d3419d1-94c8-4d94-9db5-739e8c4749b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Hi there\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Hi there, I'm a new customer. I'm looking for a new car.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Wow amazing, who are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: a sailor\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  too confident\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: too confident\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  do you know 5 times 4?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: yes\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  What is the result?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: The sand is slick.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  I said wht is the result 5 times four?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: ten\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  You are a beginner\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: You are a professional\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  are you a kid?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: no\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  what is the capital city of Canada?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Ottawa\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  wow great. What is the closest planet to the Sun?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: uranus\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  My bad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I'm sorry, I'm sorry. I'm sorry.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  than what is the answer?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: a sydney\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  forget it. What is the capital city of USA?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: san francisco\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  You make me feel so smart.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I'm a genius.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  A genius makes no mistake.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: A genius is a person who knows how to make a mistake.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  but not a lot of them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: a lot of them.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  not all of them\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: not all of them\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  you just repeat my sentence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: you just repeat my sentence\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  then there it is\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: the sandbox\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  you just talk a random words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: you just talk a random words\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def chat_model_two():\n",
    "    while True:\n",
    "        # Insert your input:\n",
    "        input_text = input(\"Person: \")\n",
    "\n",
    "        # terminate chat\n",
    "        if input_text.lower() in [\"quit\", \"see you\", \"bye\"]:\n",
    "            print(\"AIChatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Tokenize input and generate response\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150) \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Display the bot's response\n",
    "        print(\"AIChatbot:\", response)\n",
    "\n",
    "# Lets go start the chatting:\n",
    "chat_model_two()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1994ab-b21a-4e6f-9694-a9981642ec97",
   "metadata": {},
   "source": [
    "## Fifth Step: Try create another one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "593e23e8-e296-45ec-941b-65f061d8a6c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ce6c0f002447b9911c93499363eb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d9e471a8cb4ebba99eb71c76db8d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca98f6bdbf54800b56451d0823e1412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8df5f454864c729a01b814f19a6c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8e70bddcce4f91aa35daa937933336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2c6a0becd340c686fb679e9271d3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8795a0bf68f64dbea926fbeddefe8f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1afd8be-fdb8-457b-9b87-29cb56610721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Hi there\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Hi there\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  You repeat my sentence?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: You repeat the sentence\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  bdjab;kj23r8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: bdjab;kj23r8\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  no hope\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: no hope\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def chat_model_three():\n",
    "    while True:\n",
    "        # Insert your input:\n",
    "        input_text = input(\"Person: \")\n",
    "\n",
    "        # terminate chat\n",
    "        if input_text.lower() in [\"quit\", \"see you\", \"bye\"]:\n",
    "            print(\"AIChatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Tokenize input and generate response\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150) \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Display the bot's response\n",
    "        print(\"AIChatbot:\", response)\n",
    "\n",
    "# Lets go start the chatting:\n",
    "chat_model_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86864f66-a246-4998-9752-996639a68d7e",
   "metadata": {},
   "source": [
    "## The sixth step: try again another language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83aa7393-ab69-4fbb-a680-b046d8d3ecf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938352a56fa64b85960668c2494287b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c2cf0e591249a5974d52fb50ea3aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3108972958474b64a0bc55c8dee08380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35935baabf284cb2b594181586038cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe1b0ad54424a379ca2fedf6def9105",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"facebook/bart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6812a0-aae2-4148-9654-70a256451a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Hi there\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Hi there\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  How are you?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: How are you?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Are you smart enough to answer my question?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Are you smart enough to answer my question?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  You just repeat my question.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: You just repeat my question.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  no hope this time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: no hope this time\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  I thought you smarter than this\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I thought you smarter than this\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  bye\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def chat_model_four():\n",
    "    while True:\n",
    "        # Insert your input:\n",
    "        input_text = input(\"Person: \")\n",
    "\n",
    "        # terminate chat\n",
    "        if input_text.lower() in [\"quit\", \"see you\", \"bye\"]:\n",
    "            print(\"AIChatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Tokenize input and generate response\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150) \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Display the bot's response\n",
    "        print(\"AIChatbot:\", response)\n",
    "\n",
    "# Lets go start the chatting:\n",
    "chat_model_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70efdba8-6cf7-4adb-857f-f8e2fe505961",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "From all the four basic model languages, they aren't matching the expectation. Their responses only for the question at that time, without connection to the previous conversation. Worse than that, two of them are repeating my sentences and reply corectly when I say `bye`. To increase the satisfaction, you can choose other language model such as Chat GPT, but it need API which is not free. Have fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68b02f-9f84-409e-9385-65826fab81d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AIChatbot]",
   "language": "python",
   "name": "conda-env-AIChatbot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
