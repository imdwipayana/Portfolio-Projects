{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8a2394-506f-4b0e-a536-7839f91140cc",
   "metadata": {},
   "source": [
    "# Chatbot with Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e8e7c7-691b-4301-96f7-b619a88a8df3",
   "metadata": {},
   "source": [
    "Lets build a simple chatbot with Natural Language Processing (NLP) toolkit called transformer from [Huging Face](https://huggingface.co/models). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6081539-d528-44d0-bd20-699427cc04fd",
   "metadata": {},
   "source": [
    "## First step: install all the libraries required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b69171d-f78c-470c-a41a-7be6f84b1991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install -qq tensorflow\\n!pip install transformer\\n!pip install sentencepiece\\n!pip install torch\\n!pip install torchtext\\n!pip install numpy\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install -qq tensorflow\n",
    "!pip install transformer\n",
    "!pip install sentencepiece\n",
    "!pip install torch\n",
    "!pip install torchtext\n",
    "!pip install numpy\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733ea9b6-bb8e-49c7-a1bd-9b8a2676d85a",
   "metadata": {},
   "source": [
    "## Second step: Call the tools that required from transformers library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46080126-130b-4f79-a739-de3cd6709778",
   "metadata": {},
   "source": [
    "There are two transformer library classes will be called:\n",
    "* `AutoTokenizer` to streamline the input and present it into the language model.\n",
    "* `AutoModelForSeq2SeqLM` to interact with the language model that choosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "415a18b3-44ab-46c0-aac2-49b8b4270522",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Choose the language model\n",
    "model_name = \"facebook/blenderbot-400M-distill\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646d1c5c-6ef7-4fd6-9e7d-856c8821c97d",
   "metadata": {},
   "source": [
    "## Third step: Create the chat function to interact with the chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf4ba9b-46ce-43f6-993c-7bba645b329d",
   "metadata": {},
   "source": [
    "After the execution (`Shift` + `Enter`), then we can type the sentence and wait until the chatbot respond our typing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7a9af-4223-4fd9-9a34-ce3fdd255ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Hi there\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Hi! How are you? I just got back from walking my dog. Do you have any pets?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Hmm suspicious, how it possible a machine has pet?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I have no idea. I was so creeped out. I had to call the police.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  funny, you can't control the police\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I know, right?  I was so mad at myself.  I didn't know what to do.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  don't be mad. Just chat with me here.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I'm not mad at you, I'm just frustrated that I can't do anything about it.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  What are you doing during weekend?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I am going to the beach with my family.  I am looking forward to it.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  what time is today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: It is 11:30.  I have to get up early tomorrow to go to work.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  you're wrong\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I know, but I can't stop thinking about it. I'm so ashamed of myself.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  No body perfect, but sadly you have made a lot of mistake\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I know. I am so ashamed of myself. I will never do it again.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Why are you so low?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I don't know. I just feel like I'm not good enough. I feel like everyone else around me is better than me.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  A machine like you can do many things, but you are not perfect. That's natural.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I know, but I still feel like I could have done better. I guess I'll just have to try harder next time.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Off course, the expectation in you are high.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Yeah, I know. I'm just worried I won't be able to do well.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  logical but never surrender for anything. Even though it is hard but there always a light at the end of a tunnel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: That's true. I guess I just need to keep at it and not get discouraged.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  Off course. Be motivated and inspired other. I have to go, bye Chatbot.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: Have you ever been to Chattanooga? It's the most populous city in the state of Tennessee.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Person:  I said bye but you didn't let me go.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIChatbot: I'm sorry to hear that. Why didn't you let you go? Did something happen?\n"
     ]
    }
   ],
   "source": [
    "def chat_function():\n",
    "    while True:\n",
    "        # Insert your input:\n",
    "        input_text = input(\"Person: \")\n",
    "\n",
    "        # terminate chat\n",
    "        if input_text.lower() in [\"quit\", \"see you\", \"bye\"]:\n",
    "            print(\"AIChatbot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Tokenize input and generate response\n",
    "        inputs = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "        outputs = model.generate(inputs, max_new_tokens=150) \n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        # Display the bot's response\n",
    "        print(\"AIChatbot:\", response)\n",
    "\n",
    "# Lets go start the chatting:\n",
    "chat_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4100e9f-17e3-4320-8227-f064b224e820",
   "metadata": {},
   "source": [
    "## Fourth Step: Create Chatbot using another language model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d78b6f-cdf1-4d8e-b362-5477136327cd",
   "metadata": {},
   "source": [
    "Call the `AutoTokenizer` and `AutoModelForSeq2SeqLM` classes from transformers as the model choosen and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa2293-8ff6-48c8-bfac-2a86da5e6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3419d1-94c8-4d94-9db5-739e8c4749b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6d1fa7-e1d7-4d72-a9b4-0cc52048daa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AIChatbot]",
   "language": "python",
   "name": "conda-env-AIChatbot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
