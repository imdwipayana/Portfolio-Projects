{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7463c1f4-31d2-467d-a668-bbaa0474be53",
   "metadata": {},
   "source": [
    "# New York Taxi Tipping Prediction with Regression\n",
    "The data that will be used are the same as the data for classification but the target is not categorized. It means the dependent variabel will be in float. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4193074-3ed9-4d8c-87bf-083d030c452d",
   "metadata": {},
   "source": [
    "### 1. Regression on tipping in Yellow and Green Taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637348de-f55d-40e4-b595-8011fcbe6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ec0bdb6-ac49-4d5e-af3a-742655d998ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>420.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>28.440001</td>\n",
       "      <td>840.0</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.450001</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>3.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>585.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>679.0</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_count  trip_distance  total_amount  duration_seconds  tip_amount\n",
       "0                3            5.0     14.600000             420.0        2.00\n",
       "1                5           10.0     28.440001             840.0        4.74\n",
       "2                1            5.0     18.450001            1262.0        3.05\n",
       "3                1            0.0      6.700000             585.0        1.00\n",
       "4                1            2.0     10.000000             679.0        1.30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_yellow_green = \"\"\"\n",
    "WITH CTE_yellow_2009 AS (\n",
    "    SELECT \n",
    "        CAST(Trip_Pickup_DateTime AS TIMESTAMP) AS pick_up_time,\n",
    "        CAST(Trip_Dropoff_DateTime AS TIMESTAMP) AS drop_off_time,\n",
    "        CAST(Passenger_Count AS INTEGER) AS passenger_count,\n",
    "        CAST(Trip_Distance AS INTEGER) AS trip_distance,\n",
    "        Payment_Type AS payment_type,\n",
    "        CAST(Total_Amt AS FLOAT)   AS total_amount,\n",
    "        Tip_Amt AS tip_amount,\n",
    "        CAST(Tip_Amt AS FLOAT)   AS tip_amount,\n",
    "        CAST( CASE Payment_Type\n",
    "            WHEN  'Credit' THEN 1\n",
    "            WHEN  'CREDIT' THEN 1\n",
    "            ELSE 2\n",
    "        END AS INTEGER) AS payment_category\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/2009/yellow_taxi_2009/yellow_tripdata_*.parquet'\n",
    "    WHERE Trip_Pickup_DateTime IS NOT NULL\n",
    "        AND Trip_Dropoff_DateTime IS NOT NULL\n",
    "        AND Passenger_Count >= 0\n",
    "        AND Trip_Distance >= 0 \n",
    "        AND Trip_Distance <= 50\n",
    "        AND Payment_Type IS NOT NULL\n",
    "        AND Total_Amt >= 0\n",
    "        AND Tip_Amt >= 0\n",
    "        AND Trip_Pickup_DateTime >= '2009-01-01' \n",
    "        AND Trip_Pickup_DateTime < '2010-01-01'\n",
    "), CTE_duration_yellow_2009 AS (\n",
    "    SELECT\n",
    "        pick_up_time,\n",
    "        drop_off_time,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        total_amount,\n",
    "        payment_category,\n",
    "        tip_amount,\n",
    "        DATE_DIFF('day', pick_up_time, drop_off_time) AS duration_days,\n",
    "        EPOCH(drop_off_time - pick_up_time) AS duration_seconds\n",
    "    FROM CTE_yellow_2009\n",
    "    WHERE payment_category = 1\n",
    "), CTE_yellow_2010 AS (\n",
    "    SELECT \n",
    "        CAST(pickup_datetime AS TIMESTAMP) AS pick_up_time,\n",
    "        CAST(dropoff_datetime AS TIMESTAMP) AS drop_off_time,\n",
    "        CAST(passenger_count AS INTEGER) AS passenger_count,\n",
    "        CAST(total_amount AS FLOAT)   AS total_amount,\n",
    "        CAST(trip_distance AS FLOAT)   AS trip_distance,\n",
    "        payment_type,\n",
    "        tip_amount,\n",
    "        CAST( CASE payment_type\n",
    "            WHEN  'Cre' THEN 1\n",
    "            WHEN  'CRE' THEN 1\n",
    "            ELSE 2\n",
    "        END AS INTEGER) AS payment_category\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/2010/yellow_taxi_2010/yellow_tripdata_*.parquet'\n",
    "    WHERE pickup_datetime IS NOT NULL\n",
    "        AND dropoff_datetime  IS NOT NULL\n",
    "        AND passenger_count >= 0\n",
    "        AND trip_distance >= 0\n",
    "        AND trip_distance <= 50\n",
    "        AND payment_type IS NOT NULL\n",
    "        AND total_amount >= 0\n",
    "        AND tip_amount >= 0 \n",
    "        AND pickup_datetime >= '2010-01-01' \n",
    "        AND pickup_datetime < '2011-01-01'\n",
    "), CTE_duration_yellow_2010 AS (\n",
    "    SELECT\n",
    "        pick_up_time,\n",
    "        drop_off_time,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        total_amount,\n",
    "        payment_category,\n",
    "        tip_amount,\n",
    "        DATE_DIFF('day', pick_up_time, drop_off_time) AS duration_days,\n",
    "        EPOCH(drop_off_time - pick_up_time) AS duration_seconds\n",
    "    FROM CTE_yellow_2010\n",
    "    WHERE payment_category = 1\n",
    "), CTE_yellow_2011_2023 AS (\n",
    "    SELECT \n",
    "        tpep_pickup_datetime AS pick_up_time,\n",
    "        tpep_dropoff_datetime AS drop_off_time,\n",
    "        CAST(passenger_count AS INTEGER) AS passenger_count,\n",
    "        CAST(total_amount AS FLOAT)   AS total_amount,\n",
    "        CAST(trip_distance AS FLOAT)   AS trip_distance,\n",
    "        CAST(payment_type AS INTEGER) AS payment_category,\n",
    "        tip_amount\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/*/yellow_taxi/yellow_tripdata_*.parquet'\n",
    "    WHERE tpep_pickup_datetime IS NOT NULL\n",
    "        AND tpep_dropoff_datetime  IS NOT NULL\n",
    "        AND passenger_count IS NOT NULL\n",
    "        AND trip_distance >= 0\n",
    "        AND trip_distance <= 50\n",
    "        AND payment_type IS NOT NULL\n",
    "        AND total_amount >= 0\n",
    "        AND tip_amount >= 0\n",
    "        AND tpep_pickup_datetime >= '2011-01-01' \n",
    "        AND tpep_pickup_datetime < '2023-10-01'\n",
    "), CTE_duration_yellow_2011_2023 AS (\n",
    "    SELECT\n",
    "        pick_up_time,\n",
    "        drop_off_time,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        total_amount,\n",
    "        payment_category,\n",
    "        tip_amount,\n",
    "        DATE_DIFF('day', pick_up_time, drop_off_time) AS duration_days,\n",
    "        EPOCH(drop_off_time - pick_up_time) AS duration_seconds\n",
    "    FROM CTE_yellow_2011_2023\n",
    "    WHERE payment_category = 1\n",
    "), CTE_green_2011_2023 AS (\n",
    "    SELECT \n",
    "        lpep_pickup_datetime AS pick_up_time,\n",
    "        lpep_dropoff_datetime AS drop_off_time,\n",
    "        CAST(passenger_count AS INTEGER) AS passenger_count,\n",
    "        CAST(total_amount AS FLOAT)   AS total_amount,\n",
    "        CAST(trip_distance AS FLOAT)   AS trip_distance,\n",
    "        CAST(payment_type AS INTEGER) AS payment_category,\n",
    "        tip_amount\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/*/green_taxi/green_tripdata_*.parquet'\n",
    "    WHERE lpep_pickup_datetime IS NOT NULL\n",
    "        AND lpep_dropoff_datetime  IS NOT NULL\n",
    "        AND passenger_count IS NOT NULL\n",
    "        AND trip_distance >= 0\n",
    "        AND trip_distance <= 50\n",
    "        AND payment_type IS NOT NULL\n",
    "        AND total_amount >= 0\n",
    "        AND tip_amount >= 0\n",
    "        AND lpep_pickup_datetime >= '2009-01-01' \n",
    "        AND lpep_pickup_datetime < '2023-10-01'\n",
    "), CTE_duration_green_2011_2023 AS (\n",
    "    SELECT\n",
    "        pick_up_time,\n",
    "        drop_off_time,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        total_amount,\n",
    "        payment_category,\n",
    "        tip_amount,\n",
    "        DATE_DIFF('day', pick_up_time, drop_off_time) AS duration_days,\n",
    "        CAST(EPOCH(drop_off_time - pick_up_time) AS FLOAT) AS duration_seconds\n",
    "    FROM CTE_green_2011_2023\n",
    "    WHERE payment_category = 1\n",
    "), CTE_union_all AS (\n",
    "    SELECT * FROM CTE_duration_yellow_2009\n",
    "    UNION ALL\n",
    "    SELECT * FROM CTE_duration_yellow_2010\n",
    "    UNION ALL\n",
    "    SELECT * FROM CTE_duration_yellow_2011_2023\n",
    "    UNION ALL\n",
    "    SELECT * FROM CTE_duration_green_2011_2023\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    passenger_count,\n",
    "    trip_distance,\n",
    "    total_amount,\n",
    "    duration_seconds,\n",
    "    tip_amount\n",
    "FROM CTE_union_all\n",
    "WHERE (duration_days = 0) AND (duration_seconds > 0)\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "df_yellow_green = con.execute(query_yellow_green).fetchdf()\n",
    "df_yellow_green.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42cdc75-991c-4749-b98e-f60068769112",
   "metadata": {},
   "source": [
    "#### The query for data manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "957d2d3e-df1e-497e-bde4-a7aba95a1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_yellow_green = \"\"\"\n",
    "WITH CTE_yellow_2009 AS (\n",
    "    SELECT \n",
    "        CAST(Trip_Pickup_DateTime AS TIMESTAMP) AS pick_up_time,\n",
    "        CAST(Trip_Dropoff_DateTime AS TIMESTAMP) AS drop_off_time,\n",
    "        CAST(Passenger_Count AS INTEGER) AS passenger_count,\n",
    "        CAST(Trip_Distance AS INTEGER) AS trip_distance,\n",
    "        Payment_Type AS payment_type,\n",
    "        CAST(Total_Amt AS FLOAT)   AS total_amount,\n",
    "        Tip_Amt AS tip_amount,\n",
    "        CAST(Tip_Amt AS FLOAT)   AS tip_amount,\n",
    "        CAST( CASE Payment_Type\n",
    "            WHEN  'Credit' THEN 1\n",
    "            WHEN  'CREDIT' THEN 1\n",
    "            ELSE 2\n",
    "        END AS INTEGER) AS payment_category\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/2009/yellow_taxi_2009/yellow_tripdata_*.parquet'\n",
    "    WHERE Trip_Pickup_DateTime IS NOT NULL\n",
    "        AND Trip_Dropoff_DateTime IS NOT NULL\n",
    "        AND Passenger_Count >= 0\n",
    "        AND Trip_Distance >= 0 \n",
    "        AND Trip_Distance <= 50\n",
    "        AND Payment_Type IS NOT NULL\n",
    "        AND Total_Amt >= 0\n",
    "        AND Tip_Amt >= 0\n",
    "        AND Trip_Pickup_DateTime >= '2009-01-01' \n",
    "        AND Trip_Pickup_DateTime < '2010-01-01'\n",
    "), CTE_duration_yellow_2009 AS (\n",
    "    SELECT\n",
    "        pick_up_time,\n",
    "        drop_off_time,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        total_amount,\n",
    "        payment_category,\n",
    "        tip_amount,\n",
    "        DATE_DIFF('day', pick_up_time, drop_off_time) AS duration_days,\n",
    "        EPOCH(drop_off_time - pick_up_time) AS duration_seconds\n",
    "    FROM CTE_yellow_2009\n",
    "    WHERE payment_category = 1\n",
    "), CTE_yellow_2010 AS (\n",
    "    SELECT \n",
    "        CAST(pickup_datetime AS TIMESTAMP) AS pick_up_time,\n",
    "        CAST(dropoff_datetime AS TIMESTAMP) AS drop_off_time,\n",
    "        CAST(passenger_count AS INTEGER) AS passenger_count,\n",
    "        CAST(total_amount AS FLOAT)   AS total_amount,\n",
    "        CAST(trip_distance AS FLOAT)   AS trip_distance,\n",
    "        payment_type,\n",
    "        tip_amount,\n",
    "        CAST( CASE payment_type\n",
    "            WHEN  'Cre' THEN 1\n",
    "            WHEN  'CRE' THEN 1\n",
    "            ELSE 2\n",
    "        END AS INTEGER) AS payment_category\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/2010/yellow_taxi_2010/yellow_tripdata_*.parquet'\n",
    "    WHERE pickup_datetime IS NOT NULL\n",
    "        AND dropoff_datetime  IS NOT NULL\n",
    "        AND passenger_count >= 0\n",
    "        AND trip_distance >= 0\n",
    "        AND trip_distance <= 50\n",
    "        AND payment_type IS NOT NULL\n",
    "        AND total_amount >= 0\n",
    "        AND tip_amount >= 0 \n",
    "        AND pickup_datetime >= '2010-01-01' \n",
    "        AND pickup_datetime < '2011-01-01'\n",
    "), CTE_duration_yellow_2010 AS (\n",
    "    SELECT\n",
    "        pick_up_time,\n",
    "        drop_off_time,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        total_amount,\n",
    "        payment_category,\n",
    "        tip_amount,\n",
    "        DATE_DIFF('day', pick_up_time, drop_off_time) AS duration_days,\n",
    "        EPOCH(drop_off_time - pick_up_time) AS duration_seconds\n",
    "    FROM CTE_yellow_2010\n",
    "    WHERE payment_category = 1\n",
    "), CTE_yellow_2011_2023 AS (\n",
    "    SELECT \n",
    "        tpep_pickup_datetime AS pick_up_time,\n",
    "        tpep_dropoff_datetime AS drop_off_time,\n",
    "        CAST(passenger_count AS INTEGER) AS passenger_count,\n",
    "        CAST(total_amount AS FLOAT)   AS total_amount,\n",
    "        CAST(trip_distance AS FLOAT)   AS trip_distance,\n",
    "        CAST(payment_type AS INTEGER) AS payment_category,\n",
    "        tip_amount\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/*/yellow_taxi/yellow_tripdata_*.parquet'\n",
    "    WHERE tpep_pickup_datetime IS NOT NULL\n",
    "        AND tpep_dropoff_datetime  IS NOT NULL\n",
    "        AND passenger_count IS NOT NULL\n",
    "        AND trip_distance >= 0\n",
    "        AND trip_distance <= 50\n",
    "        AND payment_type IS NOT NULL\n",
    "        AND total_amount >= 0\n",
    "        AND tip_amount >= 0\n",
    "        AND tpep_pickup_datetime >= '2011-01-01' \n",
    "        AND tpep_pickup_datetime < '2023-10-01'\n",
    "), CTE_duration_yellow_2011_2023 AS (\n",
    "    SELECT\n",
    "        pick_up_time,\n",
    "        drop_off_time,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        total_amount,\n",
    "        payment_category,\n",
    "        tip_amount,\n",
    "        DATE_DIFF('day', pick_up_time, drop_off_time) AS duration_days,\n",
    "        EPOCH(drop_off_time - pick_up_time) AS duration_seconds\n",
    "    FROM CTE_yellow_2011_2023\n",
    "    WHERE payment_category = 1\n",
    "), CTE_green_2011_2023 AS (\n",
    "    SELECT \n",
    "        lpep_pickup_datetime AS pick_up_time,\n",
    "        lpep_dropoff_datetime AS drop_off_time,\n",
    "        CAST(passenger_count AS INTEGER) AS passenger_count,\n",
    "        CAST(total_amount AS FLOAT)   AS total_amount,\n",
    "        CAST(trip_distance AS FLOAT)   AS trip_distance,\n",
    "        CAST(payment_type AS INTEGER) AS payment_category,\n",
    "        tip_amount\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/*/green_taxi/green_tripdata_*.parquet'\n",
    "    WHERE lpep_pickup_datetime IS NOT NULL\n",
    "        AND lpep_dropoff_datetime  IS NOT NULL\n",
    "        AND passenger_count IS NOT NULL\n",
    "        AND trip_distance >= 0\n",
    "        AND trip_distance <= 50\n",
    "        AND payment_type IS NOT NULL\n",
    "        AND total_amount >= 0\n",
    "        AND tip_amount >= 0\n",
    "        AND lpep_pickup_datetime >= '2009-01-01' \n",
    "        AND lpep_pickup_datetime < '2023-10-01'\n",
    "), CTE_duration_green_2011_2023 AS (\n",
    "    SELECT\n",
    "        pick_up_time,\n",
    "        drop_off_time,\n",
    "        passenger_count,\n",
    "        trip_distance,\n",
    "        total_amount,\n",
    "        payment_category,\n",
    "        tip_amount,\n",
    "        DATE_DIFF('day', pick_up_time, drop_off_time) AS duration_days,\n",
    "        CAST(EPOCH(drop_off_time - pick_up_time) AS FLOAT) AS duration_seconds\n",
    "    FROM CTE_green_2011_2023\n",
    "    WHERE payment_category = 1\n",
    "), CTE_union_all AS (\n",
    "    SELECT * FROM CTE_duration_yellow_2009\n",
    "    UNION ALL\n",
    "    SELECT * FROM CTE_duration_yellow_2010\n",
    "    UNION ALL\n",
    "    SELECT * FROM CTE_duration_yellow_2011_2023\n",
    "    UNION ALL\n",
    "    SELECT * FROM CTE_duration_green_2011_2023\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    passenger_count,\n",
    "    trip_distance,\n",
    "    total_amount,\n",
    "    LOG(duration_seconds + 1) AS log_duration,\n",
    "    tip_amount\n",
    "FROM CTE_union_all\n",
    "WHERE (duration_days = 0) and (duration_seconds > 0)\n",
    "LIMIT 1000000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56aa8965-36db-48cf-b931-95114d226ca0",
   "metadata": {},
   "source": [
    "### 1.1 Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8cf4545c-ce2c-47a1-93d8-d196b4c1e1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.735155\n",
      "MSE: 2.641463\n",
      "R2: 0.309785\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from river import preprocessing, linear_model, metrics\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to DuckDB and query\n",
    "# ----------------------------\n",
    "con = duckdb.connect(\"my_data.duckdb\")\n",
    "res = con.execute(query_yellow_green)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Build regression pipeline\n",
    "# ----------------------------\n",
    "pipeline = preprocessing.StandardScaler() | linear_model.LinearRegression()\n",
    "\n",
    "# Track regression metrics\n",
    "all_metrics = metrics.MAE() + metrics.MSE() + metrics.R2()\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Streaming loop\n",
    "# ----------------------------\n",
    "while True:\n",
    "    chunk = res.fetch_df_chunk(vectors_per_chunk=50_000)\n",
    "    if chunk is None or len(chunk) == 0:\n",
    "        break\n",
    "\n",
    "    # Convert to dicts for speed\n",
    "    records = chunk.to_dict(orient=\"records\")\n",
    "\n",
    "    #chunk[\"log_duration\"] = np.log1p(chunk[\"duration_seconds\"])\n",
    "    #chunk.drop(columns=[\"duration_seconds\"], inplace=True)\n",
    "\n",
    "    #print(chunk.describe().T[[\"min\",\"max\"]].head(15))\n",
    "    #print(chunk[[\"tip_amount\"]].head(20))\n",
    "    #print(chunk[[\"tip_amount\"]].describe())\n",
    "\n",
    "    for r in records:\n",
    "        # Suppose your target column is \"tip_amount\"\n",
    "        x = {k: v for k, v in r.items() if k != \"tip_amount\"}\n",
    "        y = r[\"tip_amount\"]\n",
    "\n",
    "        # Predict\n",
    "        y_pred = pipeline.predict_one(x)\n",
    "\n",
    "        # Update metrics\n",
    "        if y_pred is not None:\n",
    "            all_metrics.update(y, y_pred)\n",
    "\n",
    "        # Train\n",
    "        pipeline.learn_one(x, y)\n",
    "\n",
    "    # Print metrics after each chunk\n",
    "    print(all_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ef8352-9a58-479e-9a40-da6bb353f5c8",
   "metadata": {},
   "source": [
    "##### Result: the R-squared is 0.309785. I think we may increase the result of r-squared to have better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e5c512-b87b-45f9-9a2c-8d59e6b45eb3",
   "metadata": {},
   "source": [
    "### 1.2 PAR-I Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e9fefd3-8bcc-4594-ac66-0f4ffee07f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.596283\n",
      "MSE: 1.637795\n",
      "R2: 0.572044\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import numpy as np\n",
    "from river import preprocessing, linear_model, metrics\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to DuckDB and query\n",
    "# ----------------------------\n",
    "con = duckdb.connect(\"my_data.duckdb\")\n",
    "res = con.execute(query_yellow_green)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Build regression pipeline\n",
    "# ----------------------------\n",
    "pipeline = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.PARegressor(C=0.01, mode=1)  \n",
    "    # mode=1 -> PA-I, mode=2 -> PA-II (try both!)\n",
    ")\n",
    "\n",
    "all_metrics = metrics.MAE() + metrics.MSE() + metrics.R2()\n",
    "\n",
    "target_col = \"tip_amount\"\n",
    "drop_cols = []\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Streaming loop\n",
    "# ----------------------------\n",
    "while True:\n",
    "    chunk = res.fetch_df_chunk(vectors_per_chunk=50_000)\n",
    "    if chunk is None or len(chunk) == 0:\n",
    "        break\n",
    "\n",
    "    records = chunk.to_dict(orient=\"records\")\n",
    "\n",
    "    for r in records:\n",
    "        x = {k: v for k, v in r.items() if k not in drop_cols + [target_col]}\n",
    "        y = r[target_col]\n",
    "\n",
    "        # Transform duration before feeding\n",
    "        if \"duration_seconds\" in x and x[\"duration_seconds\"] is not None:\n",
    "            x[\"log_duration\"] = np.log1p(x[\"duration_seconds\"])\n",
    "            del x[\"duration_seconds\"]\n",
    "\n",
    "        y_pred = pipeline.predict_one(x)\n",
    "\n",
    "        if y_pred is not None:\n",
    "            all_metrics.update(y, y_pred)\n",
    "\n",
    "        pipeline.learn_one(x, y)\n",
    "\n",
    "    print(all_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425a4862-ba88-49a3-971b-ef5bb7eb15af",
   "metadata": {},
   "source": [
    "##### Result: this is the best R-squared value amongst all models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be9f959-20b0-4f56-a34c-931db4c91f68",
   "metadata": {},
   "source": [
    "### 1.3 PAR-II Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "526f2400-c754-47b4-a339-5e14bd44f8b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.867999\n",
      "MSE: 3.236576\n",
      "R2: 0.154282\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import numpy as np\n",
    "from river import preprocessing, linear_model, metrics\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to DuckDB and query\n",
    "# ----------------------------\n",
    "con = duckdb.connect(\"my_data.duckdb\")\n",
    "res = con.execute(query_yellow_green)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Build regression pipeline\n",
    "# ----------------------------\n",
    "pipeline = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.PARegressor(C=0.01, mode=2)  \n",
    "    # mode=1 -> PA-I, mode=2 -> PA-II (try both!)\n",
    ")\n",
    "\n",
    "all_metrics = metrics.MAE() + metrics.MSE() + metrics.R2()\n",
    "\n",
    "target_col = \"tip_amount\"\n",
    "drop_cols = []\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Streaming loop\n",
    "# ----------------------------\n",
    "while True:\n",
    "    chunk = res.fetch_df_chunk(vectors_per_chunk=50_000)\n",
    "    if chunk is None or len(chunk) == 0:\n",
    "        break\n",
    "\n",
    "    records = chunk.to_dict(orient=\"records\")\n",
    "\n",
    "    for r in records:\n",
    "        x = {k: v for k, v in r.items() if k not in drop_cols + [target_col]}\n",
    "        y = r[target_col]\n",
    "\n",
    "        # Transform duration before feeding\n",
    "        if \"duration_seconds\" in x and x[\"duration_seconds\"] is not None:\n",
    "            x[\"log_duration\"] = np.log1p(x[\"duration_seconds\"])\n",
    "            del x[\"duration_seconds\"]\n",
    "\n",
    "        y_pred = pipeline.predict_one(x)\n",
    "\n",
    "        if y_pred is not None:\n",
    "            all_metrics.update(y, y_pred)\n",
    "\n",
    "        pipeline.learn_one(x, y)\n",
    "\n",
    "    print(all_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6338c-d1a7-48e2-a621-46d7c797bcda",
   "metadata": {},
   "source": [
    "##### Result: the r-squaren is decreasing drammatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b97028-7134-4c6f-b8ba-1b3b8f44c804",
   "metadata": {},
   "source": [
    "### 1.3. Linear Regression with Regularization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df1aa1bf-ffe6-46ce-9fb1-0eed138708ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.73513\n",
      "MSE: 2.64112\n",
      "R2: 0.309875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import numpy as np\n",
    "from river import preprocessing, linear_model, metrics, optim\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to DuckDB and query\n",
    "# ----------------------------\n",
    "con = duckdb.connect(\"my_data.duckdb\")\n",
    "res = con.execute(query_yellow_green)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Build regression pipeline\n",
    "# ----------------------------\n",
    "pipeline = (\n",
    "    preprocessing.StandardScaler() |\n",
    "    linear_model.LinearRegression(\n",
    "        optimizer=optim.SGD(0.01),  # learning rate\n",
    "        l2=0.0001                   # regularization strength\n",
    "    )\n",
    ")\n",
    "\n",
    "all_metrics = metrics.MAE() + metrics.MSE() + metrics.R2()\n",
    "\n",
    "target_col = \"tip_amount\"\n",
    "drop_cols = []\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Streaming loop\n",
    "# ----------------------------\n",
    "while True:\n",
    "    chunk = res.fetch_df_chunk(vectors_per_chunk=50_000)\n",
    "    if chunk is None or len(chunk) == 0:\n",
    "        break\n",
    "\n",
    "    records = chunk.to_dict(orient=\"records\")\n",
    "\n",
    "    for r in records:\n",
    "        x = {k: v for k, v in r.items() if k not in drop_cols + [target_col]}\n",
    "        y = r[target_col]\n",
    "\n",
    "        # Transform duration\n",
    "        if \"duration_seconds\" in x and x[\"duration_seconds\"] is not None:\n",
    "            x[\"log_duration\"] = np.log1p(x[\"duration_seconds\"])\n",
    "            del x[\"duration_seconds\"]\n",
    "\n",
    "        y_pred = pipeline.predict_one(x)\n",
    "\n",
    "        if y_pred is not None:\n",
    "            all_metrics.update(y, y_pred)\n",
    "\n",
    "        pipeline.learn_one(x, y)\n",
    "\n",
    "    print(all_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c34b5c-f028-4246-81e2-ef8fa404a169",
   "metadata": {},
   "source": [
    "##### Result: the R-squared is 0.30 which is far bellow with PAR-I Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9328ce7-882e-42fe-89ac-292477de5400",
   "metadata": {},
   "source": [
    "### 2. Regression on tipping in High Value for Hire Vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2fc571-5323-4bb2-8edd-d16876107597",
   "metadata": {},
   "source": [
    "### Query for data manipulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4940610-a70d-4dd4-93c7-293ab0793a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provider</th>\n",
       "      <th>duration_request</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>shared_before</th>\n",
       "      <th>shared_during</th>\n",
       "      <th>wheelchair_request</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>232.0</td>\n",
       "      <td>2.45</td>\n",
       "      <td>579</td>\n",
       "      <td>10.410000</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HV0003</td>\n",
       "      <td>921.0</td>\n",
       "      <td>1.71</td>\n",
       "      <td>490</td>\n",
       "      <td>8.809999</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>156.0</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2159</td>\n",
       "      <td>50.070000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>179</td>\n",
       "      <td>8.010000</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HV0005</td>\n",
       "      <td>207.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>1799</td>\n",
       "      <td>27.130001</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  provider  duration_request  trip_distance  duration_seconds  total_amount  \\\n",
       "0   HV0003             232.0           2.45               579     10.410000   \n",
       "1   HV0003             921.0           1.71               490      8.809999   \n",
       "2   HV0005             156.0           5.01              2159     50.070000   \n",
       "3   HV0005              96.0           0.34               179      8.010000   \n",
       "4   HV0005             207.0           6.84              1799     27.130001   \n",
       "\n",
       "  shared_before shared_during wheelchair_request  tip_amount  \n",
       "0             Y             N                  N         0.0  \n",
       "1             N             N                  N         2.0  \n",
       "2             N             Y                  N         0.0  \n",
       "3             N             Y                  N         3.0  \n",
       "4             N             Y                  N         4.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_hvfhv_2019_2023 = \"\"\"\n",
    "WITH CTE_hvfhv_2019_2023 AS (\n",
    "    SELECT \n",
    "        hvfhs_license_num AS provider,\n",
    "        request_datetime AS request_time,\n",
    "        pickup_datetime AS pick_up_time,\n",
    "        CAST(trip_miles AS FLOAT) AS trip_distance,\n",
    "        CAST(trip_time AS INTEGER) AS duration_seconds,\n",
    "        CAST(base_passenger_fare AS FLOAT) AS base_fare,\n",
    "        CAST(tolls AS FLOAT) AS toll_fare,\n",
    "        CAST(bcf AS FLOAT) AS bcf_fare,\n",
    "        CAST(sales_tax AS FLOAT) AS tax_fare,\n",
    "        CAST(tips AS FLOAT) AS tip_amount,\n",
    "        shared_request_flag AS shared_before,\n",
    "        shared_match_flag AS shared_during,\n",
    "        wav_request_flag AS wheelchair_request\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/*/high_volume_for_hire_vehicle/fhvhv_tripdata_*.parquet'\n",
    "    WHERE hvfhs_license_num IS NOT NULL\n",
    "        AND request_datetime IS NOT NULL\n",
    "        AND pickup_datetime IS NOT NULL\n",
    "        AND trip_miles >= 0\n",
    "        AND trip_miles <= 50\n",
    "        AND trip_time >= 0\n",
    "        AND base_passenger_fare >= 0\n",
    "        AND tolls >= 0\n",
    "        AND bcf >= 0\n",
    "        AND sales_tax >= 0\n",
    "        AND tips >= 0\n",
    "        AND shared_request_flag IS NOT NULL\n",
    "        AND shared_match_flag IS NOT NULL\n",
    "        AND wav_request_flag IS NOT NULL\n",
    "        AND request_datetime >= '2019-02-01' \n",
    "        AND request_datetime < '2023-10-01'\n",
    "), CTE_duration_hvfhv_2019_2023 AS (\n",
    "    SELECT\n",
    "        provider,\n",
    "        DATE_DIFF('day', request_time, pick_up_time) AS duration_days,\n",
    "        EPOCH(pick_up_time - request_time) AS duration_request,\n",
    "        trip_distance,\n",
    "        duration_seconds,\n",
    "        base_fare + toll_fare + bcf_fare + tax_fare  AS total_amount,\n",
    "        shared_before,\n",
    "        shared_during,\n",
    "        wheelchair_request,\n",
    "        tip_amount\n",
    "    FROM CTE_hvfhv_2019_2023\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    provider,\n",
    "    duration_request,\n",
    "    trip_distance,\n",
    "    duration_seconds,\n",
    "    total_amount,\n",
    "    shared_before,\n",
    "    shared_during,\n",
    "    wheelchair_request,\n",
    "    tip_amount\n",
    "FROM CTE_duration_hvfhv_2019_2023\n",
    "WHERE duration_days = 0\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "con = duckdb.connect()\n",
    "df_hvfhv_2019_2023 = con.execute(query_hvfhv_2019_2023).fetchdf()\n",
    "df_hvfhv_2019_2023.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73a5451-fb7f-407e-9dab-999d04d455d5",
   "metadata": {},
   "source": [
    "### Transform the categorical columns with one hot encoding with query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3937c337-72c9-4b27-b50f-89b9e157885d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>provider_HV0002</th>\n",
       "      <th>provider_HV0003</th>\n",
       "      <th>provider_HV0004</th>\n",
       "      <th>provider_HV0005</th>\n",
       "      <th>duration_request</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>duration_seconds</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>shared_before_yes</th>\n",
       "      <th>shared_before_no</th>\n",
       "      <th>shared_during_yes</th>\n",
       "      <th>shared_during_no</th>\n",
       "      <th>wheelchair_request_yes</th>\n",
       "      <th>wheelchair_request_no</th>\n",
       "      <th>tip_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>2.45</td>\n",
       "      <td>579</td>\n",
       "      <td>10.410000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>921</td>\n",
       "      <td>1.71</td>\n",
       "      <td>490</td>\n",
       "      <td>10.809999</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>5.01</td>\n",
       "      <td>2159</td>\n",
       "      <td>50.070000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>0.34</td>\n",
       "      <td>179</td>\n",
       "      <td>11.010000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>207</td>\n",
       "      <td>6.84</td>\n",
       "      <td>1799</td>\n",
       "      <td>31.130001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   provider_HV0002  provider_HV0003  provider_HV0004  provider_HV0005  \\\n",
       "0                0                1                0                0   \n",
       "1                0                1                0                0   \n",
       "2                0                0                0                1   \n",
       "3                0                0                0                1   \n",
       "4                0                0                0                1   \n",
       "\n",
       "   duration_request  trip_distance  duration_seconds  total_amount  \\\n",
       "0               232           2.45               579     10.410000   \n",
       "1               921           1.71               490     10.809999   \n",
       "2               156           5.01              2159     50.070000   \n",
       "3                96           0.34               179     11.010000   \n",
       "4               207           6.84              1799     31.130001   \n",
       "\n",
       "   shared_before_yes  shared_before_no  shared_during_yes  shared_during_no  \\\n",
       "0                  1                 0                  0                 1   \n",
       "1                  0                 1                  0                 1   \n",
       "2                  0                 1                  1                 0   \n",
       "3                  0                 1                  1                 0   \n",
       "4                  0                 1                  1                 0   \n",
       "\n",
       "   wheelchair_request_yes  wheelchair_request_no  tip_category  \n",
       "0                       0                      1             1  \n",
       "1                       0                      1             0  \n",
       "2                       0                      1             1  \n",
       "3                       0                      1             0  \n",
       "4                       0                      1             0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_hvfhv_2019_2023 = \"\"\"\n",
    "WITH CTE_hvfhv_2019_2023 AS (\n",
    "    SELECT \n",
    "        hvfhs_license_num AS provider,\n",
    "        request_datetime AS request_time,\n",
    "        pickup_datetime AS pick_up_time,\n",
    "        CAST(trip_miles AS FLOAT) AS trip_distance,\n",
    "        CAST(trip_time AS INTEGER) AS duration_seconds,\n",
    "        CAST(base_passenger_fare AS FLOAT) AS base_fare,\n",
    "        CAST(tolls AS FLOAT) AS toll_fare,\n",
    "        CAST(bcf AS FLOAT) AS bcf_fare,\n",
    "        CAST(sales_tax AS FLOAT) AS tax_fare,\n",
    "        CAST(tips AS FLOAT) AS tip_amount,\n",
    "        shared_request_flag AS shared_before,\n",
    "        shared_match_flag AS shared_during,\n",
    "        wav_request_flag AS wheelchair_request,\n",
    "        CAST( CASE tips\n",
    "            WHEN  0.0 THEN 1\n",
    "            ELSE 0\n",
    "        END AS INTEGER) AS tip_category\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/*/high_volume_for_hire_vehicle/fhvhv_tripdata_*.parquet'\n",
    "    WHERE hvfhs_license_num IS NOT NULL\n",
    "        AND request_datetime IS NOT NULL\n",
    "        AND pickup_datetime IS NOT NULL\n",
    "        AND trip_miles >= 0\n",
    "        AND trip_miles <= 50\n",
    "        AND trip_time >= 0\n",
    "        AND base_passenger_fare >= 0\n",
    "        AND tolls >= 0\n",
    "        AND bcf >= 0\n",
    "        AND sales_tax >= 0\n",
    "        AND tips >= 0\n",
    "        AND shared_request_flag IS NOT NULL\n",
    "        AND shared_match_flag IS NOT NULL\n",
    "        AND wav_request_flag IS NOT NULL\n",
    "        AND request_datetime >= '2019-02-01' \n",
    "        AND request_datetime < '2023-10-01'\n",
    "), CTE_duration_hvfhv_2019_2023 AS (\n",
    "    SELECT\n",
    "        provider,\n",
    "        CAST(CASE provider WHEN 'HV0002' THEN 1 ELSE 0 END AS INTEGER) AS provider_HV0002,\n",
    "        CAST(CASE provider WHEN 'HV0003' THEN 1 ELSE 0 END AS INTEGER) AS provider_HV0003,\n",
    "        CAST(CASE provider WHEN 'HV0004' THEN 1 ELSE 0 END AS INTEGER) AS provider_HV0004,\n",
    "        CAST(CASE provider WHEN 'HV0005' THEN 1 ELSE 0 END AS INTEGER) AS provider_HV0005,\n",
    "        DATE_DIFF('day', request_time, pick_up_time) AS duration_days,\n",
    "        CAST(EPOCH(pick_up_time - request_time) AS INTEGER) AS duration_request,\n",
    "        trip_distance,\n",
    "        duration_seconds,\n",
    "        base_fare + toll_fare + bcf_fare + tax_fare + tip_amount AS total_amount,\n",
    "        shared_before,\n",
    "        CAST(CASE shared_before WHEN 'Y' THEN 1 ELSE 0 END AS INTEGER) AS shared_before_yes,\n",
    "        CAST(CASE shared_before WHEN 'N' THEN 1 ELSE 0 END AS INTEGER) AS shared_before_no,\n",
    "        shared_during,\n",
    "        CAST(CASE shared_during WHEN 'Y' THEN 1 ELSE 0 END AS INTEGER) AS shared_during_yes,\n",
    "        CAST(CASE shared_during WHEN 'N' THEN 1 ELSE 0 END AS INTEGER) AS shared_during_no,\n",
    "        wheelchair_request,\n",
    "        CAST(CASE wheelchair_request WHEN 'Y' THEN 1 ELSE 0 END AS INTEGER) AS wheelchair_request_yes,\n",
    "        CAST(CASE wheelchair_request WHEN 'N' THEN 1 ELSE 0 END AS INTEGER) AS wheelchair_request_no,\n",
    "        tip_category\n",
    "    FROM CTE_hvfhv_2019_2023\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    provider_HV0002,\n",
    "    provider_HV0003,\n",
    "    provider_HV0004,\n",
    "    provider_HV0005,\n",
    "    duration_request,\n",
    "    trip_distance,\n",
    "    duration_seconds,\n",
    "    total_amount,\n",
    "    shared_before_yes,\n",
    "    shared_before_no,\n",
    "    shared_during_yes,\n",
    "    shared_during_no,\n",
    "    wheelchair_request_yes,\n",
    "    wheelchair_request_no,\n",
    "    tip_category\n",
    "FROM CTE_duration_hvfhv_2019_2023\n",
    "WHERE duration_days = 0\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "con = duckdb.connect()\n",
    "df_hvfhv_2019_2023 = con.execute(query_hvfhv_2019_2023).fetchdf()\n",
    "df_hvfhv_2019_2023.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03109163-fd87-486b-8bfb-537273f76f8a",
   "metadata": {},
   "source": [
    "### Query for batching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c0abd3e-5705-4b73-b33c-89ecfc3d7b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_hvfhv_2019_2023 = \"\"\"\n",
    "WITH CTE_hvfhv_2019_2023 AS (\n",
    "    SELECT \n",
    "        hvfhs_license_num AS provider,\n",
    "        request_datetime AS request_time,\n",
    "        pickup_datetime AS pick_up_time,\n",
    "        CAST(trip_miles AS FLOAT) AS trip_distance,\n",
    "        CAST(trip_time AS INTEGER) AS duration_seconds,\n",
    "        CAST(base_passenger_fare AS FLOAT) AS base_fare,\n",
    "        CAST(tolls AS FLOAT) AS toll_fare,\n",
    "        CAST(bcf AS FLOAT) AS bcf_fare,\n",
    "        CAST(sales_tax AS FLOAT) AS tax_fare,\n",
    "        CAST(tips AS FLOAT) AS tip_amount,\n",
    "        shared_request_flag AS shared_before,\n",
    "        shared_match_flag AS shared_during,\n",
    "        wav_request_flag AS wheelchair_request\n",
    "    FROM 'C:/Users/ekadw/Documents/DATA/NY_Taxi/*/high_volume_for_hire_vehicle/fhvhv_tripdata_*.parquet'\n",
    "    WHERE hvfhs_license_num IS NOT NULL\n",
    "        AND request_datetime IS NOT NULL\n",
    "        AND pickup_datetime IS NOT NULL\n",
    "        AND trip_miles >= 0\n",
    "        AND trip_miles <= 50\n",
    "        AND trip_time >= 0\n",
    "        AND base_passenger_fare >= 0\n",
    "        AND tolls >= 0\n",
    "        AND bcf >= 0\n",
    "        AND sales_tax >= 0\n",
    "        AND tips >= 0\n",
    "        AND shared_request_flag IS NOT NULL\n",
    "        AND shared_match_flag IS NOT NULL\n",
    "        AND wav_request_flag IS NOT NULL\n",
    "        AND request_datetime >= '2019-02-01' \n",
    "        AND request_datetime < '2023-10-01'\n",
    "), CTE_duration_hvfhv_2019_2023 AS (\n",
    "    SELECT\n",
    "        provider,\n",
    "        CAST(CASE provider WHEN 'HV0002' THEN 1 ELSE 0 END AS INTEGER) AS provider_HV0002,\n",
    "        CAST(CASE provider WHEN 'HV0003' THEN 1 ELSE 0 END AS INTEGER) AS provider_HV0003,\n",
    "        CAST(CASE provider WHEN 'HV0004' THEN 1 ELSE 0 END AS INTEGER) AS provider_HV0004,\n",
    "        CAST(CASE provider WHEN 'HV0005' THEN 1 ELSE 0 END AS INTEGER) AS provider_HV0005,\n",
    "        DATE_DIFF('day', request_time, pick_up_time) AS duration_days,\n",
    "        CAST(EPOCH(pick_up_time - request_time) AS INTEGER) AS duration_request,\n",
    "        trip_distance,\n",
    "        duration_seconds,\n",
    "        base_fare + toll_fare + bcf_fare + tax_fare + tip_amount AS total_amount,\n",
    "        shared_before,\n",
    "        CAST(CASE shared_before WHEN 'Y' THEN 1 ELSE 0 END AS INTEGER) AS shared_before_yes,\n",
    "        CAST(CASE shared_before WHEN 'N' THEN 1 ELSE 0 END AS INTEGER) AS shared_before_no,\n",
    "        shared_during,\n",
    "        CAST(CASE shared_during WHEN 'Y' THEN 1 ELSE 0 END AS INTEGER) AS shared_during_yes,\n",
    "        CAST(CASE shared_during WHEN 'N' THEN 1 ELSE 0 END AS INTEGER) AS shared_during_no,\n",
    "        wheelchair_request,\n",
    "        CAST(CASE wheelchair_request WHEN 'Y' THEN 1 ELSE 0 END AS INTEGER) AS wheelchair_request_yes,\n",
    "        CAST(CASE wheelchair_request WHEN 'N' THEN 1 ELSE 0 END AS INTEGER) AS wheelchair_request_no,\n",
    "        tip_amount\n",
    "    FROM CTE_hvfhv_2019_2023\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    provider_HV0002,\n",
    "    provider_HV0003,\n",
    "    provider_HV0004,\n",
    "    provider_HV0005,\n",
    "    LOG(duration_request + 1) AS log_duration_request,\n",
    "    LOG(trip_distance + 1) AS log_trip_distance,\n",
    "    LOG(duration_seconds + 1) AS log_duration_seconds,\n",
    "    LOG(total_amount + 1) AS log_total_amount,\n",
    "    shared_before_yes,\n",
    "    shared_before_no,\n",
    "    shared_during_yes,\n",
    "    shared_during_no,\n",
    "    wheelchair_request_yes,\n",
    "    wheelchair_request_no,\n",
    "    tip_amount\n",
    "FROM CTE_duration_hvfhv_2019_2023\n",
    "WHERE duration_days = 0\n",
    "LIMIT 1000000\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "27b81b56-6726-44fe-8530-84954dba23f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             min         max\n",
      "provider_HV0002         0.000000    1.000000\n",
      "provider_HV0003         0.000000    1.000000\n",
      "provider_HV0004         0.000000    1.000000\n",
      "provider_HV0005         0.000000    1.000000\n",
      "log_duration_request    0.845098    3.944236\n",
      "log_trip_distance       0.000000    1.707570\n",
      "log_duration_seconds    0.000000    4.534787\n",
      "log_total_amount        0.000000    2.714975\n",
      "shared_before_yes       0.000000    1.000000\n",
      "shared_before_no        0.000000    1.000000\n",
      "shared_during_yes       0.000000    1.000000\n",
      "shared_during_no        0.000000    1.000000\n",
      "wheelchair_request_yes  0.000000    1.000000\n",
      "wheelchair_request_no   0.000000    1.000000\n",
      "tip_amount              0.000000  100.000000\n",
      "MAE: 1.011807\n",
      "MSE: 3.346576\n",
      "R2: -0.177547\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from river import preprocessing, linear_model, metrics\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to DuckDB and query\n",
    "# ----------------------------\n",
    "con = duckdb.connect(\"my_data.duckdb\")\n",
    "res = con.execute(query_hvfhv_2019_2023)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Build regression pipeline\n",
    "# ----------------------------\n",
    "pipeline = linear_model.LinearRegression()\n",
    "\n",
    "# Track regression metrics\n",
    "all_metrics = metrics.MAE() + metrics.MSE() + metrics.R2()\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Streaming loop\n",
    "# ----------------------------\n",
    "while True:\n",
    "    chunk = res.fetch_df_chunk(vectors_per_chunk=50_000)\n",
    "    if chunk is None or len(chunk) == 0:\n",
    "        break\n",
    "\n",
    "    # Convert to dicts for speed\n",
    "    records = chunk.to_dict(orient=\"records\")\n",
    "\n",
    "    #chunk[\"log_duration\"] = np.log1p(chunk[\"duration_seconds\"])\n",
    "    #chunk.drop(columns=[\"duration_seconds\"], inplace=True)\n",
    "\n",
    "    print(chunk.describe().T[[\"min\",\"max\"]].head(15))\n",
    "    #print(chunk[[\"tip_amount\"]].head(20))\n",
    "    #print(chunk[[\"tip_amount\"]].describe())\n",
    "\n",
    "    for r in records:\n",
    "        # Suppose your target column is \"tip_amount\"\n",
    "        x = {k: v for k, v in r.items() if k != \"tip_amount\"}\n",
    "        y = r[\"tip_amount\"]\n",
    "\n",
    "        # Predict\n",
    "        y_pred = pipeline.predict_one(x)\n",
    "\n",
    "        # Update metrics\n",
    "        if y_pred is not None:\n",
    "            all_metrics.update(y, y_pred)\n",
    "\n",
    "        # Train\n",
    "        pipeline.learn_one(x, y)\n",
    "\n",
    "    # Print metrics after each chunk\n",
    "    print(all_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b227ad6-82d7-4e53-8a7e-ea579e9f51e0",
   "metadata": {},
   "source": [
    "##### Result: the R-squared result is negative. There is something must be done here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091e81be-4469-48cd-9395-cfa80df526b3",
   "metadata": {},
   "source": [
    "### 2.1 PAR-I Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c4cb4eb-fb83-46f1-9524-4eeb2d9dc4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.581095\n",
      "MSE: 3.015136\n",
      "R2: -0.060924\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import numpy as np\n",
    "from river import preprocessing, linear_model, metrics\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to DuckDB and query\n",
    "# ----------------------------\n",
    "con = duckdb.connect(\"my_data.duckdb\")\n",
    "res = con.execute(query_hvfhv_2019_2023)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Build regression pipeline\n",
    "# ----------------------------\n",
    "pipeline = (\n",
    "    linear_model.PARegressor(C=0.01, mode=1)  \n",
    "    # mode=1 -> PA-I, mode=2 -> PA-II (try both!)\n",
    ")\n",
    "\n",
    "all_metrics = metrics.MAE() + metrics.MSE() + metrics.R2()\n",
    "\n",
    "target_col = \"tip_amount\"\n",
    "drop_cols = []\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Streaming loop\n",
    "# ----------------------------\n",
    "while True:\n",
    "    chunk = res.fetch_df_chunk(vectors_per_chunk=50_000)\n",
    "    if chunk is None or len(chunk) == 0:\n",
    "        break\n",
    "\n",
    "    records = chunk.to_dict(orient=\"records\")\n",
    "\n",
    "    for r in records:\n",
    "        x = {k: v for k, v in r.items() if k not in drop_cols + [target_col]}\n",
    "        y = r[target_col]\n",
    "\n",
    "        # Transform duration before feeding\n",
    "        #if \"duration_seconds\" in x and x[\"duration_seconds\"] is not None:\n",
    "        #    x[\"log_duration\"] = np.log1p(x[\"duration_seconds\"])\n",
    "        #    del x[\"duration_seconds\"]\n",
    "\n",
    "        y_pred = pipeline.predict_one(x)\n",
    "\n",
    "        if y_pred is not None:\n",
    "            all_metrics.update(y, y_pred)\n",
    "\n",
    "        pipeline.learn_one(x, y)\n",
    "\n",
    "    print(all_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00775659-ec5e-455b-ad42-7b8c7c81c571",
   "metadata": {},
   "source": [
    "##### Result: R-squared is still negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6d2e3e3c-c991-44e7-94c3-dc817bfb8c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.430486\n",
      "MSE: 4.679029\n",
      "R2: -0.646392\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import duckdb\n",
    "import numpy as np\n",
    "from river import preprocessing, linear_model, metrics\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to DuckDB and query\n",
    "# ----------------------------\n",
    "con = duckdb.connect(\"my_data.duckdb\")\n",
    "res = con.execute(query_hvfhv_2019_2023)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Build regression pipeline\n",
    "# ----------------------------\n",
    "pipeline = (\n",
    "    linear_model.PARegressor(C=0.01, mode=2)  \n",
    "    # mode=1 -> PA-I, mode=2 -> PA-II (try both!)\n",
    ")\n",
    "\n",
    "all_metrics = metrics.MAE() + metrics.MSE() + metrics.R2()\n",
    "\n",
    "target_col = \"tip_amount\"\n",
    "drop_cols = []\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Streaming loop\n",
    "# ----------------------------\n",
    "while True:\n",
    "    chunk = res.fetch_df_chunk(vectors_per_chunk=50_000)\n",
    "    if chunk is None or len(chunk) == 0:\n",
    "        break\n",
    "\n",
    "    records = chunk.to_dict(orient=\"records\")\n",
    "\n",
    "    for r in records:\n",
    "        x = {k: v for k, v in r.items() if k not in drop_cols + [target_col]}\n",
    "        y = r[target_col]\n",
    "\n",
    "        # Transform duration before feeding\n",
    "        if \"duration_seconds\" in x and x[\"duration_seconds\"] is not None:\n",
    "            x[\"log_duration\"] = np.log1p(x[\"duration_seconds\"])\n",
    "            del x[\"duration_seconds\"]\n",
    "\n",
    "        y_pred = pipeline.predict_one(x)\n",
    "\n",
    "        if y_pred is not None:\n",
    "            all_metrics.update(y, y_pred)\n",
    "\n",
    "        pipeline.learn_one(x, y)\n",
    "\n",
    "    print(all_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d330b82-e775-4270-87df-35ec47ca816c",
   "metadata": {},
   "source": [
    "##### Result: the R-squared values is worse here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c1ddd15a-42d8-4341-8d37-05c6a269f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.7052770853042603\n",
      "MSE: 2.2249197959899902\n",
      "R2: 0.21712613105773926\n"
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Connect to DuckDB\n",
    "# ----------------------------\n",
    "con = duckdb.connect(\"my_data.duckdb\")\n",
    "res = con.execute(query_hvfhv_2019_2023)\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Define training params\n",
    "# ----------------------------\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"eval_metric\": \"rmse\",\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"max_depth\": 6,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"tree_method\": \"hist\",   # fast, scalable\n",
    "}\n",
    "\n",
    "num_boost_round = 500   # total boosting iterations\n",
    "batch_size = 200_000    # rows per batch\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Streaming training loop\n",
    "# ----------------------------\n",
    "bst = None\n",
    "dtest = None\n",
    "\n",
    "while True:\n",
    "    chunk = res.fetch_df_chunk(vectors_per_chunk=batch_size)\n",
    "    if chunk is None or len(chunk) == 0:\n",
    "        break\n",
    "\n",
    "    # Split features/target\n",
    "    y = chunk[\"tip_amount\"].values\n",
    "    X = chunk.drop(columns=[\"tip_amount\"])\n",
    "\n",
    "    dtrain = xgb.DMatrix(X, label=y)\n",
    "\n",
    "    if bst is None:\n",
    "        # First batch  initialize model\n",
    "        bst = xgb.train(params, dtrain, num_boost_round=50)\n",
    "    else:\n",
    "        # Subsequent batches  update model\n",
    "        bst = xgb.train(params, dtrain, num_boost_round=50, xgb_model=bst)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Evaluate on a held-out test set\n",
    "# ----------------------------\n",
    "# Load test set (smaller chunk or separate query)\n",
    "df_test = con.execute(query_hvfhv_2019_2023).fetch_df()\n",
    "y_test = df_test[\"tip_amount\"].values\n",
    "X_test = df_test.drop(columns=[\"tip_amount\"])\n",
    "dtest = xgb.DMatrix(X_test)\n",
    "\n",
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"R2:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56920a0-b9f8-4b63-aa8c-2483f652c873",
   "metadata": {},
   "source": [
    "##### Result: try the XGBoost with better value of R-squared. May be the data itself is nonlinear and some approach such as feature selection can be done here to increase the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f9d882-747e-46cd-bdda-4515f4c5346b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
